{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimised Python\n",
    "In this notebook we will look at a few useful built in methods for getting the most out of our Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(r, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate Python's performance we will use a short function\n",
    "\n",
    "As the name suggest **cart2pol** converts a pair of cartesian coordinates [x, y] to polar coordinates [r, phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Image \n",
    "Image(url='https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Polar_to_cartesian.svg/1024px-Polar_to_cartesian.svg.png',width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "y = 4\n",
    "r, phi = cart2pol(x,y)\n",
    "\n",
    "print('r   = ',r,'\\nphi = ' ,phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All well and good. However, what if we want to convert a list of cartesian coordinates to polar coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could **loop** through both lists and perform the conversion for each x-y pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol_list(list_x, list_y):\n",
    "    # Prepare empty lists for r and phi values\n",
    "    r = np.empty(len(list_x))\n",
    "    phi = np.empty(len(list_x))\n",
    "    \n",
    "    # Loop through the lists of x and y, calculating the r and phi values\n",
    "    for i in range(len(list_x)):\n",
    "        r[i] = np.sqrt(list_x[i]**2 + list_y[i]**2)\n",
    "        phi[i] = np.arctan2(list_y[i], list_x[i])\n",
    "    \n",
    "    return(r, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = np.sin(np.arange(0,2*np.pi,0.1))\n",
    "y_list = np.cos(np.arange(0,2*np.pi,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coordinates make a circle centered at [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "ax.scatter(x_list,y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list, phi_list = cart2pol_list(x_list,y_list)\n",
    "print(r_list)\n",
    "print(phi_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit time consuming to type out though, surely there is a better way to make our functions work for lists of inputs?\n",
    "\n",
    "Step forward **vectorise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart2pol_vec = np.vectorize(cart2pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list_vec, phi_list_vec = cart2pol_vec(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like magic! We can assure ourselves that these two methods produce the same answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_list == r_list_vec)\n",
    "print(phi_list == phi_list_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we could also have relied from the beginning on the fact that the numpy functions we used in our original cart2pol already accept lists and numpy arrays as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nparray = np.array(x_list)\n",
    "y_nparray = np.array(y_list)\n",
    "r,phi = cart2pol(x_nparray, y_nparray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do they perform?\n",
    "\n",
    "We can use Python's magic **%timeit** function to test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cart2pol_list(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cart2pol_vec(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cart2pol(x_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cart2pol(x_nparray, y_nparray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our experiments with `%timeit`, we learn the following:\n",
    "- It was significantly faster, both for code writing and at runtime, to use **vectorise** rather than manually looping through lists\n",
    "- Using **numpy functions** directly on arrays was 1-2 orders of magnitude faster than either of the previous two\n",
    "- It is more efficient to use **numpy arrays** than lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "Another important consideration when code becomes computationally intensive is **multiprocessing**. Python normally runs on one core, so you won't feel the full benefit of your quad-core or greater machine. You can see this when you run a section of code. To demonstrate the effect of multiprocessing we'll need some heftier maths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_maths(start=0, num=10):\n",
    "    pos = start\n",
    "    big = 1000 * 1000\n",
    "    ave = 0\n",
    "    while pos < num:\n",
    "        pos += 1\n",
    "        val = math.sqrt((pos - big) * (pos - big))\n",
    "        ave += val / num\n",
    "\n",
    "    return int(ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "do_maths(num=30000000)\n",
    "\n",
    "dt = datetime.now() - t0\n",
    "print(\"Done in {:,.2f} sec.\".format(dt.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.now()\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "processor_count = multiprocessing.cpu_count()\n",
    "# processor_count = 2 # we can Python to use a specific number of cores if desired\n",
    "\n",
    "print(f\"Computing with {processor_count} processor(s)\")\n",
    "tasks = []\n",
    "for n in range(1, processor_count + 1):\n",
    "    task = pool.apply_async(do_maths, (30000000 * (n - 1) / processor_count,\n",
    "                                      30000000 * n / processor_count))\n",
    "    \n",
    "    tasks.append(task)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "dt = datetime.now() - t0\n",
    "print(\"Done in {:,.2f} sec.\".format(dt.total_seconds()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can recover results stored in the task list with get(). This list will be in the same order as that which you used to spawn the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tasks:\n",
    "    print(t.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of a multiproccess call is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "pool = multiprocessing.Pool() # Make a pool ready to recieve tasks\n",
    "results = [] # empty list for results\n",
    "for n in range(1, processor_count + 1): # Loop for assigning a number of tasks\n",
    "    result = pool.appy_async(function, (arguments)) # make a task by passing it a function and arguments\n",
    "    results.append(result) # when result(s) of this task are ready, append them to the list\n",
    "\n",
    "pool.close() # tell async there are no more tasks coming\n",
    "pool.join() # start running the tasks concurrently\n",
    "\n",
    "for t in results:\n",
    "    t.get() # retrieve your results, You could print or assign each result to a variable for later analysis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why can't we multithread in Python?\n",
    "\n",
    "If you have experience of other programming languages, you may wonder why we can't assign tasks to multiple threads to speed up execution. We are prevented from doing this by the Global Interpreter Lock (GIL). This is a lock on the interpreter which ensures that only one thread can be in a state of execution at any one time. This is essential to protect Python's reference system that keeps track of all of the objects in memory. \n",
    "\n",
    "To get around this lock we spawn several processes which each have their own instance of the interpreter and allocated memory so cannot block one another or cause mischief with references. There's a great summary of the GIL on the real Python website [here](https://realpython.com/python-gil/)\n",
    "\n",
    "**tl;dr** multithreading won't speed up your compute heavy calcualtions as only one thread can execute at any time. Use multiprocessing instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "Multiprocessing example adapted from [Talk Python To Me Training: async techniques](https://training.talkpython.fm/courses/details/async-in-python-with-threading-and-multiprocessing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
